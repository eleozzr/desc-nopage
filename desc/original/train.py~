# Copyright 2018 Xiangjie Li
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

#from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os,math
import time
import random
import numpy as np
import tensorflow as tf
from anndata import AnnData
import scanpy.api as sc
from keras import backend as K
import keras
try:
    from .load_mnist import load_mnist
    from .DESC import *
except:
    #just for test
    from load_mnist import load_mnist
    from DESC import *

#check use gpu
#if len(K.tensorflow_backend._get_available_gpus()):
#if tf.test.is_gpu_available():
#config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,inter_op_parallelism_threads=num_cores,
#    allow_soft_placement=True,device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})
#session = tf.Session(config=config)
#K.set_session(session)
#os.environ['CUDA_VISIBLE_DEVICES']=K.tensorflow_backend._get_available_gpus()[0][-1]#use first GPUid


#or 
def getdims(x=(10000,200)):
    """
    return the dims for network
    """
    assert len(x)==2
    n_sample=x[0]
    if n_sample>20000:# may be need complex network
        dims=[x[-1],128,32]
    elif n_sample>10000:#10000
        dims=[x[-1],64,32]
    elif n_sample>5000: #5000
        dims=[x[-1],32,16] #16
    elif n_sample>2000:
        dims=[x[-1],128]
    elif n_sample>500:
        dims=[x[-1],64]
    else:
        dims=[x[-1],16]
    #dims=[x[-1],64,32] if n_sample>10000 else [x[-1],32,16]
    return dims



    
def train_single(data,dims=None,
        alpha=1.0,
        tol=0.005,
        init='glorot_uniform',
        n_clusters=None,
        louvain_resolution=1.0,
        n_neighbors=15,
        pretrain_epochs=300,
        batch_size=256,
        activation='relu',
        actinlayer1='tanh',
        drop_rate_SAE=0.2,
        is_stacked=True,
        use_earlyStop=True,
        save_dir='result_tmp',
        max_iter=1000,
        epochs_fit=4, 
        num_Cores=20,
        use_GPU=True,
        random_seed=201809,
        verbose=True,
):
    if isinstance(data,AnnData):
        x=data.X
        adata=data.copy()
    else:
        x=data
        adata=sc.AnnData(data)
    #make sure dims 
    if dims is None:
        dims=getdims(x.shape)
    assert dims[0]==x.shape[-1],'the number of columns of x doesnot equal to the first element of dims, we must make sure that dims[0]==x.shape[0]'
    #if use_GPU and tf.test.is_gpu_available():
#set seed
    random.seed(random_seed)
    np.random.seed(random_seed)
    tf.set_random_seed(random_seed)
    if use_GPU:
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"
        #os.environ['CUDA_VISIBLE_DEVICES']=K.tensorflow_backend._get_available_gpus()[0][-1]#use first GPUid
    else:
        #set only use cpu
        os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
        import multiprocessing
        total_cpu=multiprocessing.cpu_count()
        print('The number of cpu in your computer is',total_cpu)
        num_Cores=int(num_Cores) if total_cpu>int(num_Cores) else int(math.ceil(total_cpu/2)) 
        K.set_session(tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=num_Cores, inter_op_parallelism_threads=num_Cores)))

  
    tic=time()#recored time         
    desc=DESC(dims=dims,
              x=x,
              init=init,
              n_clusters=n_clusters,
              louvain_resolution=louvain_resolution,
              n_neighbors=n_neighbors,
              pretrain_epochs=pretrain_epochs,
              batch_size=batch_size,
              activation=activation,
              actinlayer1=actinlayer1,
              drop_rate_SAE=drop_rate_SAE,
              is_stacked=is_stacked,
              use_earlyStop=use_earlyStop,
              save_dir=save_dir
    )
    desc.compile(optimizer=SGD(0.01,0.9),loss='kld')
    Embeded_z,q_pred=desc.fit(maxiter=max_iter,epochs_fit=epochs_fit)
    #
    print("The desc has been trained successfully!!!!!!")
    if verbose:
        print("The summary of desc model is:")
        desc.model.summary()
    print("The runtime is ",time()-tic)
    y_pred=pd.Series(np.argmax(q_pred,axis=1),dtype='category')
    y_pred.cat.categories=list(range(len(y_pred.unique())))
    adata.obs['desc_'+str(louvain_resolution)]=y_pred
    adata.obsm['X_Embeded_z'+str(louvain_resolution)]=Embeded_z
    #prob_matrix
    adata.uns['prob_matrix'+str(louvain_resolution)]=q_pred
    return adata


def train(data,dims=None,
        alpha=1.0,
        tol=0.005,
        init='glorot_uniform',
        n_clusters=None,
        louvain_resolution=[0.8,1.0,1.2],
        n_neighbors=15,
        pretrain_epochs=300,
        batch_size=256,
        activation='relu',
        actinlayer1='tanh',
        drop_rate_SAE=0.2,
        is_stacked=True,
        use_earlyStop=True,
        save_dir='result_tmp',
        max_iter=1000,
        epochs_fit=4, 
        num_Cores=20,
        use_GPU=True,
        random_seed=201809,
        verbose=True
): 
    if isinstance(louvain_resolution,str):
        louvain_resolution=list(map(float,louvain_resolution.split(",")))
    else:
        assert isinstance(louvain_resolution,list),'louvain_resolution must be either a string with spearator "," or a list like [1.0,2.0,3.0] '
        louvain_resolution=list(map(float,louvain_resolution))
    #
    time_start=time()
    for resolution in louvain_resolution:
        print("Start to process resolution=",str(resolution))
        res=train_single(data=data,
            dims=dims,
            alpha=alpha,
            tol=tol,
            init=init,
            n_clusters=n_clusters,
            louvain_resolution=resolution,
            n_neighbors=n_neighbors,
            pretrain_epochs=pretrain_epochs,
            batch_size=batch_size,
            activation=activation,
            actinlayer1=actinlayer1,
            drop_rate_SAE=drop_rate_SAE,
            is_stacked=is_stacked,
            use_earlyStop=use_earlyStop,
            save_dir=save_dir,
            max_iter=max_iter,
            epochs_fit=epochs_fit, 
            num_Cores=num_Cores,
            use_GPU=use_GPU,
            random_seed=random_seed,
            verbose=verbose)
        #update adata
        data=res
    print("The run time for all resolution is ",time()-time_start)
    return data


if __name__=='__main__':
    import argparse
    parser = argparse.ArgumentParser(description='just for simple test train.py',formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--use_GPU', default=True, type=bool)
    args = parser.parse_args()
    print(args)
    x,y=load_mnist(sample_size=10000,seed=0)
    print ('MNIST use ', x.shape)
    #adata=train_single(x,dims,louvain_resolution=0.4,use_GPU=True)
    dims=[x.shape[-1],64,32]
    adata=train(x,dims,louvain_resolution=[0.2,0.4],use_GPU=False)
    print(adata)
         
    
  



